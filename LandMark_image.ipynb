{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FDNzqThNsgPa"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "# import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import os\n",
        "import dlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA is available\n",
            "TensorFlow version: 2.10.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Check if CUDA is available\n",
        "if tf.test.is_built_with_cuda():\n",
        "    print(\"CUDA is available\")\n",
        "    # Enable GPU memory growth (optional)\n",
        "    physical_devices = tf.config.list_physical_devices('GPU')\n",
        "    for device in physical_devices:\n",
        "        tf.config.experimental.set_memory_growth(device, False)\n",
        "else:\n",
        "    print(\"CUDA is not available\")\n",
        "\n",
        "# Check TensorFlow version\n",
        "print(\"TensorFlow version:\", tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import zipfile\n",
        "# zip_ref = zipfile.ZipFile('fercnn.zip', 'r')\n",
        "# zip_ref.extractall('/content')\n",
        "# zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "train_path = r'E:\\project\\KDEF\\train'\n",
        "val_path = r'E:\\project\\KDEF\\test'\n",
        "\n",
        "\n",
        "# Define desired image dimensions\n",
        "img_height = 224\n",
        "img_width = 224\n",
        "\n",
        "def load_images_from_folder(folder):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for emotion_folder in os.listdir(folder):\n",
        "        emotion_path = os.path.join(folder, emotion_folder)\n",
        "        if os.path.isdir(emotion_path):\n",
        "            for image_filename in os.listdir(emotion_path):\n",
        "                img_path = os.path.join(emotion_path, image_filename)\n",
        "                img = cv2.imread(img_path)  # Use cv2 to read images\n",
        "                if img is not None:\n",
        "                    # Resize image to desired dimensions if needed\n",
        "                    img = cv2.resize(img, (img_height, img_width))\n",
        "                    images.append(img)\n",
        "                    labels.append(emotion_folder)  # Assuming folder names are the labels\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "X_train, y_train = load_images_from_folder(train_path)\n",
        "X_val, y_val = load_images_from_folder(val_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "nbYP2NqesqC6"
      },
      "outputs": [],
      "source": [
        "def save_images_to_folder(images, labels, output_folder):\n",
        "    # Iterate through each image and label pair\n",
        "    for image, label in zip(images, labels):\n",
        "        # Create the corresponding label folder in the output folder\n",
        "        output_label_folder = os.path.join(output_folder, label)\n",
        "        os.makedirs(output_label_folder, exist_ok=True)\n",
        "\n",
        "        # Save the image to the output folder\n",
        "        output_path = os.path.join(output_label_folder, f\"{len(os.listdir(output_label_folder))}.jpg\")\n",
        "        cv2.imwrite(output_path, image)\n",
        "\n",
        "# Define the output folders\n",
        "output_train_folder = r'E:\\KDEF\\ResizedKDEF_train'\n",
        "output_val_folder = r'E:\\KDEF\\ResizedKDEF_validation'\n",
        "\n",
        "# Save the training and validation images to the output folders\n",
        "save_images_to_folder(X_train, y_train, output_train_folder)\n",
        "save_images_to_folder(X_val, y_val, output_val_folder)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "_LNStkVi1DRI"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Load the pre-trained shape predictor model\n",
        "predictor_path = 'shape_predictor_68_face_landmarks.dat'\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "predictor = dlib.shape_predictor(predictor_path)\n",
        "\n",
        "# Function to detect facial landmarks in an image\n",
        "def detect_landmarks(image):\n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    # Detect faces in the grayscale image\n",
        "    faces = detector(gray)\n",
        "    landmarks = []\n",
        "    # Iterate through each detected face\n",
        "    for face in faces:\n",
        "        # Detect facial landmarks\n",
        "        shape = predictor(gray, face)\n",
        "        # Convert the landmarks to a list of tuples\n",
        "        landmarks.append([(shape.part(i).x, shape.part(i).y) for i in range(shape.num_parts)])\n",
        "    return landmarks\n",
        "\n",
        "def apply_landmark_detection(input_folder, output_folder):\n",
        "    # Iterate through each subfolder (emotion) in the input folder\n",
        "    for emotion_folder in os.listdir(input_folder):\n",
        "        emotion_folder_path = os.path.join(input_folder, emotion_folder)\n",
        "        if os.path.isdir(emotion_folder_path):\n",
        "            # Create the corresponding emotion folder in the output folder\n",
        "            output_emotion_folder = os.path.join(output_folder, emotion_folder)\n",
        "            os.makedirs(output_emotion_folder, exist_ok=True)\n",
        "\n",
        "            # Iterate through each image in the emotion folder\n",
        "            for filename in os.listdir(emotion_folder_path):\n",
        "                if filename.endswith('.jpg') or filename.endswith('.png'):\n",
        "                    # Read the image\n",
        "                    image_path = os.path.join(emotion_folder_path, filename)\n",
        "                    image = cv2.imread(image_path)\n",
        "\n",
        "                    # Detect landmarks in the image\n",
        "                    landmarks = detect_landmarks(image)\n",
        "\n",
        "                    # Process or analyze the landmarks as needed\n",
        "                    # For example, you can draw the landmarks on the image and save it\n",
        "                    for landmark_set in landmarks:\n",
        "                        for landmark in landmark_set:\n",
        "                            cv2.circle(image, landmark, 1, (0, 0, 255), -1)  # Draw a red dot at each landmark\n",
        "\n",
        "                    # Save the image with landmarks in the output folder\n",
        "                    output_path = os.path.join(output_emotion_folder, f\"landmarked_{filename}\")\n",
        "                    cv2.imwrite(output_path, image)\n",
        "\n",
        "# Set the input and output folders for resized train and test images\n",
        "input_resized_train_folder = r'E:\\KDEF\\ResizedKDEF_train'\n",
        "input_resized_test_folder = r'E:\\KDEF\\ResizedKDEF_validation'\n",
        "output_landmarked_train_folder = r'E:\\KDEF\\landmarked_ResizedKDEF_train'\n",
        "output_landmarked_test_folder = r'E:\\KDEF\\landmarked_ResizedKDEF_validation'\n",
        "\n",
        "# Apply landmark detection to resized train and test images and save in new folders\n",
        "apply_landmark_detection(input_resized_train_folder, output_landmarked_train_folder)\n",
        "apply_landmark_detection(input_resized_test_folder, output_landmarked_test_folder)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# input_resized_train_folder = '/content/resized_train'\n",
        "# input_resized_test_folder = '/content/resized_val'\n",
        "output_landmarked_train_folder = '/inception/resized_train'\n",
        "output_landmarked_test_folder = '/inception/resized2_val'"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
